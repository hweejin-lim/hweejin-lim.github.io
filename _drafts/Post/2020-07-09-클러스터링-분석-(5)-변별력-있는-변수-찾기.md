---
layout: post
title: 클러스터링 분석 - (5) 변별력 있는 변수 찾기
summary: 군집화에 효과적인 변수를 찾는 방법에 대하여 생각해 봅니다.
featured-img: iris5
categories: 클러스터링분석 주성분분석 상관계수
mathjax: true
---

기계학습(machine learning)에서는 분석 목적과 데이터 특성에 맞는 적절한 알고리즘을 선택하고 매개변수를 잘 조정하는 것도 중요하지만, **좋은 입력 데이터를 만들기 위해 적절한 변수를 찾는 것이 더욱 중요**합니다. 해결해야 할 문제와 사용할 데이터의 연관성이 낮으면 아무리 최신 알고리즘을 적용한다고 할 지라도 좋은 결과를 기대할 수 없을테니까요. 이것은 예측 분석뿐만 아니라 클러스터링 분석에서도 마찬가지입니다. 이번 시간에는 더 나은 군집화 결과를 만들 수 있도록 변별력 높은 변수를 찾아가는 과정에 대하여 알아보도록 하겠습니다.


<br>
#### *- 클러스터링 분석, 다른 이야기들 -*

아래는 클러스터링 분석과 관련하여 다루었던 다른 이야기들입니다. 참고로 보시면 좋을 것 같아요.

[1]:https://hweejin-lim.github.io/%ED%81%B4%EB%9F%AC%EC%8A%A4%ED%84%B0%EB%A7%81-%EB%B6%84%EC%84%9D-(1)-%EB%B2%94%EC%A3%BC%ED%98%95-%EB%B3%80%EC%88%98/
[2]:https://hweejin-lim.github.io/%ED%81%B4%EB%9F%AC%EC%8A%A4%ED%84%B0%EB%A7%81-%EB%B6%84%EC%84%9D-(2)-%EA%B2%B0%EC%B8%A1%EA%B0%92/
[3]:https://hweejin-lim.github.io/%ED%81%B4%EB%9F%AC%EC%8A%A4%ED%84%B0%EB%A7%81-%EB%B6%84%EC%84%9D-(3)-%EC%8A%A4%EC%BC%80%EC%9D%BC-%EC%A1%B0%EC%A0%95/
[4]:https://hweejin-lim.github.io/%ED%81%B4%EB%9F%AC%EC%8A%A4%ED%84%B0%EB%A7%81-%EB%B6%84%EC%84%9D-(4)-%EC%A0%81%EC%A0%95-%EA%B5%B0%EC%A7%91%EC%88%98(k)-%EC%B0%BE%EA%B8%B0/
[5]:hhtps:
[클러스터링 분석 - (1) 범주형 변수][1]  
[클러스터링 분석 - (2) 결측값][2]  
[클러스터링 분석 - (3) 스케일 조정][3]  
[클러스터링 분석 - (4) 적정 군집수(k) 찾기][4]    
[클러스터링 분석 - (5) 변별력 있는 변수 찾기][5]    

<br>

### 너무 많은 변수를 사용할 위험

클러스터링 분석은 데이터 전처리를 위해 사용하기도 하지만 군집화 결과 자체를 현업에 활용하기 위한 목적으로 많이 사용합니다. 대표적인 사례가 몇 차례 말씀드렸던 **고객 세분화(customer segmentation)**인데요, 보통 이런 작업을 진행할 때는 데이터 분석가와 현업 담당자들이 모여 고객을 유형화하는데 필요할 것으로 생각되는 특징이나 변수에 대한 아이디어 수집, 토론 과정을 거치게 됩니다. 이 과정에서 다양한 의견이 나오기 마련이고, 여기서 **논의된 특징 혹은 변수들은 대개 입력 데이터에 모두 포함하여 분석**을 진행하게 됩니다. 논의된 변수를 모두 데이터셋에 집어넣게 되는 이유는 다음과 같은 것들을 들 수 있습니다.     

1. '정답이 없는' 비지도학습(unsupervised learning)의 특성 때문에 어떤 변수가 좋은 변수인지 판단하기 어려움     
2. 변수를 이것저것 다 넣으면 '기계가 알아서 잘 판별해주겠지' 하는 기대심리     
3. 의견을 제시한 사람에 대한 존중(?)     

이런 이유들 때문에 고객 세분화를 위한 클러스터링 분석에서는 일반적으로 굉장히 많은 변수가 담긴 데이터셋을 사용하게 됩니다. 하지만, **너무 많은 변수를 사용하게 되면 아래와 같은 몇 가지 문제**가 발생하게 됩니다.     

1. 알고리즘 학습(model fitting) 시간 증가
2. 모델이 복잡해지면서 [과적합(overfitting)]('https://ko.wikipedia.org/wiki/%EA%B3%BC%EC%A0%81%ED%95%A9') 위험 증가
3. 군집화 결과 검토의 복잡성 증가 (군집별로 비교해서 봐야할 변수가 늘어나기 때문)

이런 문제를 최소화하려면 알고리즘 학습 이전과 이후, 변수를 정리하는 과정을 거칠 필요가 있습니다. 먼저 알고리즘 학습 전(데이터셋 완성 이후)에 변수를 정리하는 방안에 대해 이야기해보도록 할께요.    


<br> 

### 변수간의 관계 미리보기

변수 논의 과정에서는 많은 변수들이 등장하다보니 **서로 유사성이 높은 것들**도 존재하고, **한 변수가 다른 변수에 많은 영향**을 주는 변수들도 있기 마련입니다. 분석용 데이터셋이 완성되면 **상관계수 히트맵**을 그려봄으로써 변수간의 이러한 관계에 대해 좀더 쉽게 들여다 볼 수 있습니다.     

```python
### 필요한 모듈 불러오기
%matplotlib inline	# 시각화 결과를 Jupyter Notebook에서 바로 보기
import matplotlib.pyplot as plt    # 모듈 불러오기

### 상관계수 테이블
corr = df.corr()    # 'df'라는 데이터셋을 'corr'라는 이름의 상관계수 테이블로 저장 

### 상관계수 히트맵 그리기

# 히트맵 사이즈 설정
plt.figure(figsize = (20, 15))	

# 히트맵 형태 정의. 여기서는 삼각형 형태(위 쪽 삼각형에 True, 아래 삼각형에 False)
mask = np.zeros_like(corr, dtype=np.bool) 
mask[np.triu_indices_from(mask)] = True

# 히트맵 그리기
sns.heatmap(data = corr,    # 'corr' = 상관계수 테이블
            annot = True,  # 히트맵에 값 표시
            mask=mask,   # 히트맵 형태. 여기서는 위에서 정의한 삼각형 형태
            fmt = '.2f',   # 값 표시 방식. 소숫점 2번째자리까지 
            linewidths = 1.,  # 경계면 실선 구분 여부
            cmap = 'RdYlBu_r')  # 사용할 색 지정 ('python colormap 검색')
plt.title('상관계수 히트맵')
plt.show()
```
![corr](https://drive.google.com/uc?id=1ILBGTeM8XPRYx5K3WK8Oa9JcjSTnfAzF)    

히트맵을 그린 후 아래와 같은 과정을 통해 분석에 활용할 변수의 수를 줄일 수 있습니다.     

1. **특히 높은 상관을 보이는 변수 묶음(들)이 있는지 확인**    
2. **묶음별로 상대적으로 중요도가 낮다고 판단되는 변수는 분석에서 제외 검토하기**    

위의 예시에서도 특정 변수 하나가 다른 여러개의 변수와 높은 상관을 보이는 케이스가 발견되네요. 이런 경우에 변수간의 중요도를 고려하여 일부 변수를 제외하는 것을 고려해 볼 수 있습니다. 물론 모든 변수가 그 나름대로의 의미를 갖고 있다고 판단되면 모두 활용할 수도 있습니다. 이런 과정들을 통해 사전에 분석에 소요되는 시간을 줄이고, 클러스터링 모델의 복잡성을 낮출 수 있습니다.     

<br>


### 주성분분석(Principle Components Analysis)

이번에는 군집화 결과를 이용하여 변수의 중요도를 검토하는 방법입니다.   







<br>






















